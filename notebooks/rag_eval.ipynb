{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lastmile-utils 0.0.24 requires python-dotenv==1.0.0, but you have python-dotenv 1.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tracing-auto-instrumentation[langchain] in ./.venv/lib/python3.11/site-packages (0.0.10)\n",
      "Requirement already satisfied: html2text in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (2024.2.26)\n",
      "Requirement already satisfied: lastmile-eval in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.0.71)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (2.1.2)\n",
      "Requirement already satisfied: pyarrow in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (16.1.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (4.66.4)\n",
      "Requirement already satisfied: wget in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (3.2)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.2.7)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.2.7)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.2.13)\n",
      "Requirement already satisfied: langchain-experimental in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.0.62)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.1.15)\n",
      "Requirement already satisfied: numexpr in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (2.10.1)\n",
      "Requirement already satisfied: openinference-instrumentation-langchain in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (0.1.21)\n",
      "Requirement already satisfied: wikipedia in ./.venv/lib/python3.11/site-packages (from tracing-auto-instrumentation[langchain]) (1.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (3.9.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (0.1.82)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain->tracing-auto-instrumentation[langchain]) (8.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core->tracing-auto-instrumentation[langchain]) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core->tracing-auto-instrumentation[langchain]) (24.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.11/site-packages (from langchain-community->tracing-auto-instrumentation[langchain]) (0.6.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in ./.venv/lib/python3.11/site-packages (from langchain-openai->tracing-auto-instrumentation[langchain]) (1.35.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.11/site-packages (from langchain-openai->tracing-auto-instrumentation[langchain]) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (1.0.1)\n",
      "Requirement already satisfied: result in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.16.0)\n",
      "Requirement already satisfied: lastmile-utils in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.0.24)\n",
      "Requirement already satisfied: evaluate==0.4.1 in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.4.1)\n",
      "Requirement already satisfied: arize-phoenix-evals==0.5.0 in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.5.0)\n",
      "Requirement already satisfied: instructor in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (1.3.4)\n",
      "Requirement already satisfied: random-word in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (1.0.11)\n",
      "Requirement already satisfied: rouge-score in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.1.2)\n",
      "Requirement already satisfied: opentelemetry-api in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-sdk in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.46b0)\n",
      "Requirement already satisfied: openinference-semantic-conventions in ./.venv/lib/python3.11/site-packages (from lastmile-eval->tracing-auto-instrumentation[langchain]) (0.1.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->tracing-auto-instrumentation[langchain]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->tracing-auto-instrumentation[langchain]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas->tracing-auto-instrumentation[langchain]) (2024.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in ./.venv/lib/python3.11/site-packages (from arize-phoenix-evals==0.5.0->lastmile-eval->tracing-auto-instrumentation[langchain]) (4.12.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.venv/lib/python3.11/site-packages (from evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (2.20.0)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.11/site-packages (from evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.venv/lib/python3.11/site-packages (from evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.21.4)\n",
      "Requirement already satisfied: responses<0.19 in ./.venv/lib/python3.11/site-packages (from evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.18.0)\n",
      "Requirement already satisfied: openinference-instrumentation>=0.1.7 in ./.venv/lib/python3.11/site-packages (from openinference-instrumentation-langchain->tracing-auto-instrumentation[langchain]) (0.1.8)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in ./.venv/lib/python3.11/site-packages (from openinference-instrumentation-langchain->tracing-auto-instrumentation[langchain]) (0.46b0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from openinference-instrumentation-langchain->tracing-auto-instrumentation[langchain]) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (from wikipedia->tracing-auto-instrumentation[langchain]) (4.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->tracing-auto-instrumentation[langchain]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->tracing-auto-instrumentation[langchain]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->tracing-auto-instrumentation[langchain]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->tracing-auto-instrumentation[langchain]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->tracing-auto-instrumentation[langchain]) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->tracing-auto-instrumentation[langchain]) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->tracing-auto-instrumentation[langchain]) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->tracing-auto-instrumentation[langchain]) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->tracing-auto-instrumentation[langchain]) (3.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai->tracing-auto-instrumentation[langchain]) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai->tracing-auto-instrumentation[langchain]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai->tracing-auto-instrumentation[langchain]) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai->tracing-auto-instrumentation[langchain]) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->tracing-auto-instrumentation[langchain]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->tracing-auto-instrumentation[langchain]) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->tracing-auto-instrumentation[langchain]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain->tracing-auto-instrumentation[langchain]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain->tracing-auto-instrumentation[langchain]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain->tracing-auto-instrumentation[langchain]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain->tracing-auto-instrumentation[langchain]) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->tracing-auto-instrumentation[langchain]) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai->tracing-auto-instrumentation[langchain]) (2024.5.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia->tracing-auto-instrumentation[langchain]) (2.5)\n",
      "Requirement already satisfied: docstring-parser<0.17,>=0.16 in ./.venv/lib/python3.11/site-packages (from instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.16)\n",
      "Requirement already satisfied: jiter<0.5.0,>=0.4.1 in ./.venv/lib/python3.11/site-packages (from instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.4.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in ./.venv/lib/python3.11/site-packages (from instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (13.7.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in ./.venv/lib/python3.11/site-packages (from instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.12.3)\n",
      "Requirement already satisfied: black==23.11.0 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (23.11.0)\n",
      "Requirement already satisfied: chardet==5.2.0 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (5.2.0)\n",
      "Requirement already satisfied: flake8==6.1.0 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (6.1.0)\n",
      "Requirement already satisfied: isort==5.12.0 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (5.12.0)\n",
      "Requirement already satisfied: pylint==3.0.2 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.0.2)\n",
      "Requirement already satisfied: pyright==1.1.335 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.1.335)\n",
      "Requirement already satisfied: pytest==7.4.3 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (7.4.3)\n",
      "Collecting python-dotenv (from lastmile-eval->tracing-auto-instrumentation[langchain])\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: autoflake==2.2.1 in ./.venv/lib/python3.11/site-packages (from lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (2.2.1)\n",
      "Requirement already satisfied: pyflakes>=3.0.0 in ./.venv/lib/python3.11/site-packages (from autoflake==2.2.1->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.1.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.11/site-packages (from black==23.11.0->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./.venv/lib/python3.11/site-packages (from black==23.11.0->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.11/site-packages (from black==23.11.0->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in ./.venv/lib/python3.11/site-packages (from black==23.11.0->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (4.2.2)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from flake8==6.1.0->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in ./.venv/lib/python3.11/site-packages (from flake8==6.1.0->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (2.11.1)\n",
      "Requirement already satisfied: astroid<=3.1.0-dev0,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from pylint==3.0.2->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.0.3)\n",
      "Requirement already satisfied: tomlkit>=0.10.1 in ./.venv/lib/python3.11/site-packages (from pylint==3.0.2->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.13.0)\n",
      "Requirement already satisfied: nodeenv>=1.6.0 in ./.venv/lib/python3.11/site-packages (from pyright==1.1.335->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.9.1)\n",
      "Requirement already satisfied: iniconfig in ./.venv/lib/python3.11/site-packages (from pytest==7.4.3->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in ./.venv/lib/python3.11/site-packages (from pytest==7.4.3->lastmile-utils->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.5.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api->lastmile-eval->tracing-auto-instrumentation[langchain]) (7.1.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.25.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.25.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.63.2)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.64.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.25.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in ./.venv/lib/python3.11/site-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-grpc==1.25.0->opentelemetry-exporter-otlp->lastmile-eval->tracing-auto-instrumentation[langchain]) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain->tracing-auto-instrumentation[langchain]) (65.5.0)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.11/site-packages (from rouge-score->lastmile-eval->tracing-auto-instrumentation[langchain]) (2.1.0)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (from rouge-score->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.8.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.15.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai->tracing-auto-instrumentation[langchain]) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai->tracing-auto-instrumentation[langchain]) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.11/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich<14.0.0,>=13.7.0->instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.9.0->instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.5.4)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk->rouge-score->lastmile-eval->tracing-auto-instrumentation[langchain]) (1.4.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->lastmile-eval->tracing-auto-instrumentation[langchain]) (0.1.2)\n",
      "Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.0.1\n",
      "    Uninstalling python-dotenv-1.0.1:\n",
      "      Successfully uninstalled python-dotenv-1.0.1\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U langchain langchain-community langchain-chroma langchain-openai faiss-cpu\n",
    "%pip install -q -U langchain_experimental lastmile-eval \"lastmile-eval[ui]\"\n",
    "%pip install -q -U python-dotenv\n",
    "%pip install \"tracing-auto-instrumentation[langchain]\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Splitting documents...\n",
      "Creating embeddings...\n",
      "Done loading documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader \n",
    "from langchain_community.document_loaders.text import TextLoader \n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# from tracing_auto_instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "# # Create an instance of LangChainInstrumentor and instrument the code\n",
    "# instrumentor = LangChainInstrumentor(project_name=\"RAG Eval Test\")\n",
    "# instrumentor.instrument()\n",
    "\n",
    "print(\"Loading documents...\")\n",
    "knowledgeDirectoryPath = \"knowledge/structured\"\n",
    "loader = DirectoryLoader(knowledgeDirectoryPath, glob=\"**/*.*\", loader_cls=TextLoader) \n",
    "loaded_docs = loader.load() \n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\") \n",
    "\n",
    "print(\"Splitting documents...\")\n",
    "#splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \n",
    "splitter = SemanticChunker(embeddings)\n",
    "chunks = splitter.split_documents(loaded_docs) \n",
    "\n",
    "print(\"Creating embeddings...\")\n",
    "vector_store = Chroma.from_documents(chunks, embeddings) \n",
    "\n",
    "print(\"Done loading documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(query):\n",
    "    # Get documents similar to the query ith their scores\n",
    "    docs_and_score = vector_store.similarity_search_with_score(query, k=5)\n",
    "    \n",
    "    # Remove duplicates and unrelated documents\n",
    "    unique_docs = []\n",
    "    unique_docs_and_score = []\n",
    "    seen = set()\n",
    "    ordered_byScore = sorted(docs_and_score, key=lambda x: x[1])\n",
    "    for doc in ordered_byScore:\n",
    "        content = doc[0].page_content\n",
    "        score = doc[1]\n",
    "        if score < 1 and content not in seen:\n",
    "            unique_docs.append(content)\n",
    "            unique_docs_and_score.append(doc)\n",
    "            seen.add(content)\n",
    "            \n",
    "    context = \"\\n\\n\".join(unique_docs)\n",
    "    \n",
    "    return context, unique_docs_and_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send query to retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'knowledge/structured/Your First 48 Hours - Darnell Self Captions.md'}, page_content=\"Get around the most successful associates. ## Fast Start Qualification\\nWe want to get you paid and promoted, called fast start qualified. The company gives you 20 days to earn your bonuses. Why not do it in your first two days? ## Getting Customers\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level. ## Accessing Information\\nGain access to information quickly. There are videos that will show you how to launch and structure your business. ## Three-Way Calls\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\nYou have access to many resources in your back office. Gain that information and education to become more competent and confident. ## Conclusion\\nI'm excited for you. I can't wait to celebrate your first rank advancement. Welcome again to the PPLSI family. \"),\n",
       "  0.8507039546966553),\n",
       " (Document(metadata={'source': 'knowledge/structured/Darnell Self Zoom Presentation Captions.md'}, page_content=\"Being in the right rooms is important. ## Proximity Has Power\\n\\nGet around the most successful associates. Our company has a hybrid model, so some events will be in person and some via Zoom. Attend these events to learn from the best. ## Fast Start Qualification\\n\\nWe want to get you paid and promoted. We call it fast start qualified. The company gives you 20 days to become fast start qualified and earn your bonuses. Many people wait until the last two days, but why not do it in your first two days? ## Getting Customers\\n\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level because you've already hit your first rank and gotten paid. ## Accessing Information\\n\\nGain access to as much information as fast as you can. There are several videos that will show you how to launch your business, structure it, and answer questions. ## Three-Way Calls\\n\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\n\\nToday, you have access to many resources right in your back office. Gain that information and education to become more competent and confident.\"),\n",
       "  0.8598235249519348)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context, results = retrieve_docs(\"I'm a new associate. What should I do to be successful?\")\n",
    "# context, results = retrieve_docs(\"What is the capital of Argentina?\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send query to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] 2024-07-10 20:59:09,297 __init__.py:518: Overriding of current TracerProvider is not allowed\n",
      "[DEBUG] 2024-07-10 20:59:09,299 connectionpool.py:1051: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-07-10 20:59:09,299 connectionpool.py:1051: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-07-10 20:59:09,672 connectionpool.py:546: https://lastmileai.dev:443 \"GET /api/evaluation_projects/list?name=RAG+Test+4 HTTP/11\" 200 344\n",
      "[WARNING] 2024-07-10 20:59:09,700 __init__.py:518: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from lastmile_eval.rag.debugger.tracing import get_lastmile_tracer\n",
    "from lastmile_eval.rag.debugger.common.types import RagFlowType\n",
    "from lastmile_eval.rag.debugger.api import LastMileTracer\n",
    "\n",
    "SCOPED_PROMPT = \"\"\"\n",
    "If the answer to the user's question is not contained in the provided context, answer 🤷.\n",
    "\"\"\"\n",
    "# If the answer to the user question is not contained in the provided context and cannot be inferred from it, \n",
    "# answer 🤷.\n",
    "# \"\"\"\n",
    "\n",
    "USE_MARKDOWN_PROMPT = \"\"\"\n",
    "Use Markdown to format your response.\n",
    "\"\"\"\n",
    "\n",
    "TRANSPARENT_CONTEXT = \"\"\"\n",
    "Do not mention the context in your answer.\n",
    "\"\"\"\n",
    "\n",
    "PROJECT_NAME = \"RAG Test 4\"\n",
    "\n",
    "# Instantiate LastMile Tracer object\n",
    "tracer: LastMileTracer = get_lastmile_tracer(\n",
    "    tracer_name=\"my-tracer\",\n",
    "    project_name=PROJECT_NAME,\n",
    "    rag_flow_type=RagFlowType.QUERY,\n",
    ")\n",
    "\n",
    "tracer: LastMileTracer = get_lastmile_tracer(\"My-Project\")\n",
    "\n",
    "def get_prompt(instructions, scoped_answer, use_markdown, context):\n",
    "    content = instructions \\\n",
    "        + TRANSPARENT_CONTEXT \\\n",
    "        + (SCOPED_PROMPT if scoped_answer else \"\") \\\n",
    "        + (USE_MARKDOWN_PROMPT if use_markdown else \"\") \\\n",
    "        + \"\\nContext:\\n\" + context \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(content=content),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "@tracer.trace_function()\n",
    "def get_response(query, modelfamily, model, instructions, scoped_answer, use_markdown, temperature):    \n",
    "    client = get_client(modelfamily, model, temperature)\n",
    "    context, docs_with_scores = retrieve_docs(query)\n",
    "    prompt = get_prompt(instructions, scoped_answer, use_markdown, context)\n",
    "\n",
    "    chain = prompt | client\n",
    "    response = chain.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "    \n",
    "    metadata = get_metadata(modelfamily, model, response)\n",
    "    \n",
    "    # Log query event to the trace\n",
    "    tracer.add_query_event(\n",
    "        query=query,\n",
    "        llm_output=response.content,\n",
    "        system_prompt=\"system prompt\",\n",
    "        metadata={\"llm_name\": model, \"temperature\": temperature, \"model_family\": modelfamily},\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"content\": response.content,\n",
    "        \"docs_with_scores\": docs_with_scores,\n",
    "        \"metadata\": metadata,\n",
    "        \"prompt\": prompt,\n",
    "        }\n",
    "    \n",
    "def get_client(model_family, model, temperature):\n",
    "    if model_family == \"openai\":\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        model = ChatOpenAI(model=model, temperature=temperature)\n",
    "    elif model_family == \"anthropic\":\n",
    "        from langchain_anthropic import ChatAnthropic\n",
    "        model = ChatAnthropic(model=model, temperature=temperature)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_family} not recognized\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_metadata(model_family, model, response):\n",
    "    if model_family == \"anthropic\":\n",
    "        usage = {k: v for k, v in response.response_metadata[\"usage\"].items() if k in (\"input_tokens\", \"output_tokens\")}\n",
    "    elif model_family == \"openai\":\n",
    "        usage = {k: v for k, v in response.usage_metadata.items() if k in (\"input_tokens\", \"output_tokens\")}\n",
    "    else:\n",
    "        raise ValueError(f\"Model family {model_family} not recognized\")\n",
    "    \n",
    "    total_tokens = usage[\"input_tokens\"] + usage[\"output_tokens\"]\n",
    "\n",
    "    return {\"model\": model, **usage, \"total_tokens\": total_tokens}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] 2024-07-10 20:59:09,709 _config.py:80: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "[DEBUG] 2024-07-10 20:59:09,710 _config.py:146: load_verify_locations cafile='/Users/raggif/python/streamit/hello_streamlit/.venv/lib/python3.11/site-packages/certifi/cacert.pem'\n",
      "[DEBUG] 2024-07-10 20:59:09,762 _config.py:80: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "[DEBUG] 2024-07-10 20:59:09,763 _config.py:146: load_verify_locations cafile='/Users/raggif/python/streamit/hello_streamlit/.venv/lib/python3.11/site-packages/certifi/cacert.pem'\n",
      "[DEBUG] 2024-07-10 20:59:09,777 _base_client.py:447: Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x138c67a60>, 'json_data': {'input': [[40, 2846, 264, 502, 22712, 13, 3639, 1288, 358, 656, 311, 387, 6992, 30]], 'model': 'text-embedding-3-large', 'encoding_format': 'base64'}}\n",
      "[DEBUG] 2024-07-10 20:59:09,779 _base_client.py:959: Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "[DEBUG] 2024-07-10 20:59:09,779 _trace.py:45: close.started\n",
      "[DEBUG] 2024-07-10 20:59:09,780 _trace.py:45: close.complete\n",
      "[DEBUG] 2024-07-10 20:59:09,780 _trace.py:45: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "[DEBUG] 2024-07-10 20:59:09,798 _trace.py:45: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1311380d0>\n",
      "[DEBUG] 2024-07-10 20:59:09,798 _trace.py:45: start_tls.started ssl_context=<ssl.SSLContext object at 0x11d914cb0> server_hostname='api.openai.com' timeout=None\n",
      "[DEBUG] 2024-07-10 20:59:09,822 _trace.py:45: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x13244d7d0>\n",
      "[DEBUG] 2024-07-10 20:59:09,822 _trace.py:45: send_request_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:09,823 _trace.py:45: send_request_headers.complete\n",
      "[DEBUG] 2024-07-10 20:59:09,824 _trace.py:45: send_request_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:09,825 _trace.py:45: send_request_body.complete\n",
      "[DEBUG] 2024-07-10 20:59:09,825 _trace.py:45: receive_response_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:10,017 _trace.py:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 11 Jul 2024 03:59:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-model', b'text-embedding-3-large'), (b'openai-organization', b'user-xmumiywg6wliupnqplzyzgro'), (b'openai-processing-ms', b'45'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999985'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_068bd34e4f339231380e0c91a7351487'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a15e1171807769a-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "[INFO] 2024-07-10 20:59:10,018 _client.py:1026: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[DEBUG] 2024-07-10 20:59:10,019 _trace.py:45: receive_response_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:10,069 _trace.py:45: receive_response_body.complete\n",
      "[DEBUG] 2024-07-10 20:59:10,070 _trace.py:45: response_closed.started\n",
      "[DEBUG] 2024-07-10 20:59:10,071 _trace.py:45: response_closed.complete\n",
      "[DEBUG] 2024-07-10 20:59:10,072 _base_client.py:998: HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Thu, 11 Jul 2024 03:59:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'text-embedding-3-large', 'openai-organization': 'user-xmumiywg6wliupnqplzyzgro', 'openai-processing-ms': '45', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999985', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_068bd34e4f339231380e0c91a7351487', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8a15e1171807769a-SEA', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "[DEBUG] 2024-07-10 20:59:10,073 _base_client.py:1006: request_id: req_068bd34e4f339231380e0c91a7351487\n",
      "[DEBUG] 2024-07-10 20:59:10,085 _base_client.py:447: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"\\nDo not mention the context in your answer.\\n\\nIf the answer to the user's question is not contained in the provided context, answer 🤷.\\n\\nUse Markdown to format your response.\\n\\nContext:\\nGet around the most successful associates. ## Fast Start Qualification\\nWe want to get you paid and promoted, called fast start qualified. The company gives you 20 days to earn your bonuses. Why not do it in your first two days? ## Getting Customers\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level. ## Accessing Information\\nGain access to information quickly. There are videos that will show you how to launch and structure your business. ## Three-Way Calls\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\nYou have access to many resources in your back office. Gain that information and education to become more competent and confident. ## Conclusion\\nI'm excited for you. I can't wait to celebrate your first rank advancement. Welcome again to the PPLSI family. \\n\\nBeing in the right rooms is important. ## Proximity Has Power\\n\\nGet around the most successful associates. Our company has a hybrid model, so some events will be in person and some via Zoom. Attend these events to learn from the best. ## Fast Start Qualification\\n\\nWe want to get you paid and promoted. We call it fast start qualified. The company gives you 20 days to become fast start qualified and earn your bonuses. Many people wait until the last two days, but why not do it in your first two days? ## Getting Customers\\n\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level because you've already hit your first rank and gotten paid. ## Accessing Information\\n\\nGain access to as much information as fast as you can. There are several videos that will show you how to launch your business, structure it, and answer questions. ## Three-Way Calls\\n\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\n\\nToday, you have access to many resources right in your back office. Gain that information and education to become more competent and confident.\", 'role': 'system'}, {'content': \"I'm a new associate. What should I do to be successful?\", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "[DEBUG] 2024-07-10 20:59:10,086 _base_client.py:959: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "[DEBUG] 2024-07-10 20:59:10,086 _trace.py:45: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "[DEBUG] 2024-07-10 20:59:10,106 _trace.py:45: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x138be6990>\n",
      "[DEBUG] 2024-07-10 20:59:10,106 _trace.py:45: start_tls.started ssl_context=<ssl.SSLContext object at 0x110744440> server_hostname='api.openai.com' timeout=None\n",
      "[DEBUG] 2024-07-10 20:59:10,136 _trace.py:45: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x138c3e010>\n",
      "[DEBUG] 2024-07-10 20:59:10,137 _trace.py:45: send_request_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:10,138 _trace.py:45: send_request_headers.complete\n",
      "[DEBUG] 2024-07-10 20:59:10,139 _trace.py:45: send_request_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:10,141 _trace.py:45: send_request_body.complete\n",
      "[DEBUG] 2024-07-10 20:59:10,141 _trace.py:45: receive_response_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:12,654 _trace.py:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 11 Jul 2024 03:59:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-xmumiywg6wliupnqplzyzgro'), (b'openai-processing-ms', b'2358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59362'), (b'x-ratelimit-reset-requests', b'11.085s'), (b'x-ratelimit-reset-tokens', b'638ms'), (b'x-request-id', b'req_8c73bd376d86e1947bd1eff1ccd589bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=O9lgO52KkP4d7yCU4XR1pr3u4EuZK7PO1N7xK1pCRpY-1720670352-1.0.1.1-R6bmvsxkdxDepdM61uTe86UCCS6CxvCd6poDTpllTY2LKAp75.YlikcUd1tp16tgyiGzxuwcSxfZUYue85lwNw; path=/; expires=Thu, 11-Jul-24 04:29:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qpajNGdyr3POykkjhl625Vncqsf30okb.uhbAH.asQI-1720670352744-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a15e1191ab8a36e-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "[INFO] 2024-07-10 20:59:12,655 _client.py:1026: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[DEBUG] 2024-07-10 20:59:12,656 _trace.py:45: receive_response_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-07-10 20:59:12,657 _trace.py:45: receive_response_body.complete\n",
      "[DEBUG] 2024-07-10 20:59:12,657 _trace.py:45: response_closed.started\n",
      "[DEBUG] 2024-07-10 20:59:12,658 _trace.py:45: response_closed.complete\n",
      "[DEBUG] 2024-07-10 20:59:12,659 _base_client.py:998: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Thu, 11 Jul 2024 03:59:12 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-organization', 'user-xmumiywg6wliupnqplzyzgro'), ('openai-processing-ms', '2358'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '60000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '59362'), ('x-ratelimit-reset-requests', '11.085s'), ('x-ratelimit-reset-tokens', '638ms'), ('x-request-id', 'req_8c73bd376d86e1947bd1eff1ccd589bd'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=O9lgO52KkP4d7yCU4XR1pr3u4EuZK7PO1N7xK1pCRpY-1720670352-1.0.1.1-R6bmvsxkdxDepdM61uTe86UCCS6CxvCd6poDTpllTY2LKAp75.YlikcUd1tp16tgyiGzxuwcSxfZUYue85lwNw; path=/; expires=Thu, 11-Jul-24 04:29:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('set-cookie', '_cfuvid=qpajNGdyr3POykkjhl625Vncqsf30okb.uhbAH.asQI-1720670352744-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8a15e1191ab8a36e-SEA'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "[DEBUG] 2024-07-10 20:59:12,659 _base_client.py:1006: request_id: req_8c73bd376d86e1947bd1eff1ccd589bd\n",
      "[DEBUG] 2024-07-10 20:59:12,849 connectionpool.py:546: https://lastmileai.dev:443 \"POST /api/trace/create HTTP/11\" 200 10\n",
      "[DEBUG] 2024-07-10 20:59:12,853 connectionpool.py:1051: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-07-10 20:59:13,227 connectionpool.py:546: https://lastmileai.dev:443 \"POST /api/rag_query_traces/create HTTP/11\" 200 None\n",
      "[DEBUG] 2024-07-10 20:59:13,230 connectionpool.py:1051: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-07-10 20:59:13,600 connectionpool.py:546: https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/11\" 200 None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': \"To be successful as a new associate, here are some key steps you can take:\\n\\n1. **Fast Start Qualification**: Aim to become fast start qualified within the first two days by getting three customers and one business partner. This will boost your belief level and set you on the path to success.\\n\\n2. **Getting Customers**: Focus on acquiring customers and building relationships. One of your customers might even transition into becoming an associate, further enhancing your success.\\n\\n3. **Accessing Information**: Make use of the available resources like videos to quickly learn how to launch and structure your business effectively.\\n\\n4. **Networking**: Surround yourself with successful associates. Attend events, whether in person or via Zoom, to learn from the best and gain valuable insights.\\n\\n5. **Continuous Learning**: Take advantage of the resources in your back office for continuous learning. The more informed and educated you are, the more competent and confident you'll become in your role.\\n\\nBy following these steps and staying committed to your growth and development, you'll be on the right track towards achieving success as a new associate. 🚀\",\n",
       " 'docs_with_scores': [(Document(metadata={'source': 'knowledge/structured/Your First 48 Hours - Darnell Self Captions.md'}, page_content=\"Get around the most successful associates. ## Fast Start Qualification\\nWe want to get you paid and promoted, called fast start qualified. The company gives you 20 days to earn your bonuses. Why not do it in your first two days? ## Getting Customers\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level. ## Accessing Information\\nGain access to information quickly. There are videos that will show you how to launch and structure your business. ## Three-Way Calls\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\nYou have access to many resources in your back office. Gain that information and education to become more competent and confident. ## Conclusion\\nI'm excited for you. I can't wait to celebrate your first rank advancement. Welcome again to the PPLSI family. \"),\n",
       "   0.850750207901001),\n",
       "  (Document(metadata={'source': 'knowledge/structured/Darnell Self Zoom Presentation Captions.md'}, page_content=\"Being in the right rooms is important. ## Proximity Has Power\\n\\nGet around the most successful associates. Our company has a hybrid model, so some events will be in person and some via Zoom. Attend these events to learn from the best. ## Fast Start Qualification\\n\\nWe want to get you paid and promoted. We call it fast start qualified. The company gives you 20 days to become fast start qualified and earn your bonuses. Many people wait until the last two days, but why not do it in your first two days? ## Getting Customers\\n\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level because you've already hit your first rank and gotten paid. ## Accessing Information\\n\\nGain access to as much information as fast as you can. There are several videos that will show you how to launch your business, structure it, and answer questions. ## Three-Way Calls\\n\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\n\\nToday, you have access to many resources right in your back office. Gain that information and education to become more competent and confident.\"),\n",
       "   0.8598432540893555)],\n",
       " 'metadata': {'model': 'gpt-3.5-turbo',\n",
       "  'input_tokens': 516,\n",
       "  'output_tokens': 219,\n",
       "  'total_tokens': 735},\n",
       " 'prompt': ChatPromptTemplate(input_variables=['messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessage(content=\"\\nDo not mention the context in your answer.\\n\\nIf the answer to the user's question is not contained in the provided context, answer 🤷.\\n\\nUse Markdown to format your response.\\n\\nContext:\\nGet around the most successful associates. ## Fast Start Qualification\\nWe want to get you paid and promoted, called fast start qualified. The company gives you 20 days to earn your bonuses. Why not do it in your first two days? ## Getting Customers\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level. ## Accessing Information\\nGain access to information quickly. There are videos that will show you how to launch and structure your business. ## Three-Way Calls\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\nYou have access to many resources in your back office. Gain that information and education to become more competent and confident. ## Conclusion\\nI'm excited for you. I can't wait to celebrate your first rank advancement. Welcome again to the PPLSI family. \\n\\nBeing in the right rooms is important. ## Proximity Has Power\\n\\nGet around the most successful associates. Our company has a hybrid model, so some events will be in person and some via Zoom. Attend these events to learn from the best. ## Fast Start Qualification\\n\\nWe want to get you paid and promoted. We call it fast start qualified. The company gives you 20 days to become fast start qualified and earn your bonuses. Many people wait until the last two days, but why not do it in your first two days? ## Getting Customers\\n\\nTo get fast start qualified, you need three customers and one business partner. One of those customers might become an associate. This increases your belief level because you've already hit your first rank and gotten paid. ## Accessing Information\\n\\nGain access to as much information as fast as you can. There are several videos that will show you how to launch your business, structure it, and answer questions. ## Three-Way Calls\\n\\nUse three-way calls to get expert help in answering questions. This way, you learn while your prospect gets the answers they need. ## Continuous Learning\\n\\nToday, you have access to many resources right in your back office. Gain that information and education to become more competent and confident.\"), MessagesPlaceholder(variable_name='messages')])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\n",
    "    \"I'm a new associate. What should I do to be successful?\",                  # query\n",
    "    \"openai\",                                                                   # Model family\n",
    "    \"gpt-3.5-turbo\",                                                            # Model\n",
    "    \"\",                                                                         # Instructions       \n",
    "    True,                                                                       # Scoped answer    \n",
    "    True,                                                                       # Use markdown\n",
    "    0                                                                           # Temperature  \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
